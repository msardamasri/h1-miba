{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b5e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 1. IMPORTS\n",
    "# ======================================================\n",
    "# These are the required libraries for data processing, visualization,\n",
    "# and machine learning preprocessing.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 2. CLEANING FUNCTION\n",
    "# ======================================================\n",
    "# This function:\n",
    "# - Drops unwanted columns\n",
    "# - Removes columns with more than 60% missing values\n",
    "# - Fills numeric missing values with median\n",
    "# - Fills categorical missing values with mode\n",
    "# - Removes numeric outliers using IQR\n",
    "# The goal is to prepare a clean dataset for analysis.\n",
    "\n",
    "def clean_df(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Drop columns we don’t need\n",
    "    columns_to_drop = [\"number_of_reviews_ltm\", \"reviews_per_month\"]\n",
    "    df = df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n",
    "    # Drop columns with >60% missing values\n",
    "    thresh = len(df) * 0.40\n",
    "    df = df.dropna(axis=1, thresh=thresh)\n",
    "\n",
    "    # Fill missing values\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in [\"float64\", \"int64\"]:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "        else:\n",
    "            mode_vals = df[col].mode()\n",
    "            df[col] = df[col].fillna(mode_vals[0] if len(mode_vals) else \"unknown\")\n",
    "\n",
    "    # Remove outliers with IQR\n",
    "    numeric_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "    for col in numeric_cols:\n",
    "        Q1, Q3 = df[col].quantile(0.25), df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "        df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8872562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 3. FEATURE TYPE DETECTION\n",
    "# ======================================================\n",
    "# This helper function returns two lists:\n",
    "# - Numeric columns\n",
    "# - Categorical columns\n",
    "\n",
    "def get_feature_types(df):\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    return numeric_cols, categorical_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 4. PLOTTING FUNCTIONS\n",
    "# ======================================================\n",
    "# These helper functions visualize numeric and categorical columns.\n",
    "\n",
    "def plot_numeric_features(df):\n",
    "    numeric_cols, _ = get_feature_types(df)\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        # Histogram\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(df[col], kde=True)\n",
    "        plt.title(f\"Histogram: {col}\")\n",
    "\n",
    "        # Boxplot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.boxplot(x=df[col])\n",
    "        plt.title(f\"Boxplot: {col}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_categorical_features(df, max_unique=20):\n",
    "    _, categorical_cols = get_feature_types(df)\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        if df[col].nunique() <= max_unique:\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            df[col].value_counts().plot(kind='bar')\n",
    "            plt.title(f\"Categorical: {col}\")\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368962e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 5. LOAD & MERGE DATASETS\n",
    "# ======================================================\n",
    "# In this step:\n",
    "# - We load CSV datasets (10% sample to reduce RAM usage)\n",
    "# - Merge them using listing_id / id\n",
    "# The output is a combined raw dataframe.\n",
    "\n",
    "print(\"Sampling & merging datasets...\")\n",
    "\n",
    "df3 = pd.read_csv(\"calendar.csv.gz\").sample(frac=0.1, random_state=42)\n",
    "df2 = pd.read_csv(\"reviews.csv.gz\").sample(frac=0.1, random_state=42)\n",
    "df1 = pd.read_csv(\"listings.csv.gz\").sample(frac=0.1, random_state=42)\n",
    "\n",
    "df5 = pd.merge(df3, df1, how=\"inner\", left_on=\"listing_id\", right_on=\"id\")\n",
    "df = pd.merge(df5, df2, how=\"inner\", on=\"listing_id\")\n",
    "\n",
    "print(\"Merged dataframe shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 6. CLEAN MERGED DATAFRAME\n",
    "# ======================================================\n",
    "# Apply our cleaning pipeline to the merged dataframe.\n",
    "\n",
    "print(\"\\nCleaning merged dataframe...\")\n",
    "df_clean = clean_df(df)\n",
    "print(\"Cleaned dataframe shape:\", df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a6a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 7. ONE-HOT ENCODING + SCALING (ML READY)\n",
    "# ======================================================\n",
    "# This final step transforms:\n",
    "# - Categorical columns → OneHotEncoder\n",
    "# - Numeric columns → StandardScaler\n",
    "# Output is ML‑ready.\n",
    "\n",
    "print(\"\\nApplying OneHotEncoder + StandardScaler (ML preprocessing)...\")\n",
    "\n",
    "numeric_cols, categorical_cols = get_feature_types(df_clean)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False), categorical_cols),\n",
    "        (\"scale\", StandardScaler(), numeric_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "df_processed = preprocessor.fit_transform(df_clean)\n",
    "\n",
    "# Build feature name list\n",
    "feature_names = (\n",
    "    list(preprocessor.named_transformers_[\"onehot\"]\n",
    "         .get_feature_names_out(categorical_cols))\n",
    "    +\n",
    "    numeric_cols\n",
    ")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_processed = pd.DataFrame(df_processed, columns=feature_names)\n",
    "\n",
    "df_processed.to_csv(\"merged_encoded_scaled_ml_ready.csv\", index=False)\n",
    "\n",
    "print(\"\\n ML-ready encoded + scaled dataset saved as: merged_encoded_scaled_ml_ready.csv\")\n",
    "print(\"Pipeline completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
